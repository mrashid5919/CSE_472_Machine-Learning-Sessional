{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your file choice: 1/2/3\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter your file choice: 1/2/3\")\n",
    "choice=int(input())\n",
    "if choice==1:\n",
    "    dataframe=pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "#dataframe\n",
    "#print(dataframe.head(),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(ch,df):\n",
    "    #replace empty string values with NaN\n",
    "    df = df.replace(\" \", np.nan)\n",
    "    #replace missing values with columnwise mean for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include='number')\n",
    "    df[numeric_cols.columns] = numeric_cols.fillna(numeric_cols.mean())\n",
    "    #replace missing values with columnwise mode for non-numeric columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude='number')\n",
    "    df[non_numeric_cols.columns] = non_numeric_cols.fillna(non_numeric_cols.mode().iloc[0])\n",
    "    #remove duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    if ch==1:\n",
    "        features=dataframe.drop('Churn',axis=1)\n",
    "        features.drop('customerID',axis=1,inplace=True)\n",
    "        target=dataframe['Churn']\n",
    "\n",
    "    #label encoding target column\n",
    "    encoder=LabelEncoder()\n",
    "    target=encoder.fit_transform(target)\n",
    "\n",
    "    #one hot encoding the categorical columns\n",
    "    categorical_columns=[col for col in features if features[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        features=pd.get_dummies(features, columns=[col], drop_first=True)\n",
    "\n",
    "    #min-max scaling the numeric columns\n",
    "    scaler=MinMaxScaler()\n",
    "    scale_columns=features.select_dtypes(exclude=['bool']).columns\n",
    "    features[scale_columns]=scaler.fit_transform(features[scale_columns])\n",
    "\n",
    "    features_df=pd.DataFrame(features,columns=features.columns)\n",
    "    target_df=pd.DataFrame(target,columns=['Churn'])\n",
    "    correlations=features_df.corrwith(target_df['Churn'])\n",
    "\n",
    "    return features_df,target_df,correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processed, target_processed, correlations=preprocessing(choice,dataframe)\n",
    "norm=Normalizer()\n",
    "feature_normalized=norm.fit_transform(feature_processed)\n",
    "#feature_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_correlations=correlations.abs().sort_values(ascending=False).head(20)\n",
    "\n",
    "feature_processed_df=pd.DataFrame(feature_normalized,columns=feature_processed.columns)\n",
    "feature_processed_df=feature_processed_df[top_20_correlations.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_processed_df, target_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hypothesis function (Logistic regression)\n",
    "def predict(X, weights, bias):\n",
    "    return sigmoid(np.dot(X, weights) + bias)\n",
    "\n",
    "# Cost function (Binary Cross-Entropy)\n",
    "def compute_cost(X, y, weights, bias):\n",
    "    m = X.shape[0]  # number of examples\n",
    "    predictions = predict(X, weights, bias)\n",
    "    cost = -(1/m) * np.sum(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent to update weights and bias\n",
    "def gradient_descent(X, y, weights, bias, learning_rate, iterations):\n",
    "    m = X.shape[0]  # number of examples\n",
    "    for i in range(iterations):\n",
    "        # Calculate predictions\n",
    "        predictions = predict(X, weights, bias)\n",
    "        \n",
    "        # Compute the gradients\n",
    "        dw = (1/m) * np.dot(X.T, (predictions - y))\n",
    "        db = (1/m) * np.sum(predictions - y)\n",
    "        \n",
    "        # Update the weights and bias\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "    \n",
    "    return weights, bias\n",
    "\n",
    "# Function to make predictions (classify as 0 or 1)\n",
    "def classify(X, weights, bias, threshold=0.5):\n",
    "    probabilities = predict(X, weights, bias)\n",
    "    return [1 if p >= threshold else 0 for p in probabilities]\n",
    "\n",
    "# Initialize weights and bias\n",
    "weights = np.zeros(X_train.shape[1])\n",
    "bias = 0\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "# Train the model\n",
    "weights, bias = gradient_descent(X_train, np.array(y_train).flatten(), weights, bias, learning_rate, iterations)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred = classify(X_test, weights, bias)\n",
    "\n",
    "# Output accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Logistic Regression classifier: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging classifier: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "num_bootstrap_samples=9\n",
    "bootstrap_samples=[]\n",
    "\n",
    "X_train_np = X_train.to_numpy()  # Convert X_train to a NumPy array\n",
    "\n",
    "for i in range(num_bootstrap_samples):\n",
    "    bootstrap_indices=np.random.choice(range(len(X_train)),len(X_train),replace=True)\n",
    "    bootstrap_X=X_train.iloc[bootstrap_indices]\n",
    "    bootstrap_y=y_train.iloc[bootstrap_indices]\n",
    "    bootstrap_samples.append((bootstrap_X, bootstrap_y))\n",
    "\n",
    "lr_models=[]\n",
    "for x,y in bootstrap_samples:\n",
    "    clf=LogisticRegression()\n",
    "    clf.fit(x,y)\n",
    "    lr_models.append(clf)\n",
    "\n",
    "predictions=[]\n",
    "for model in lr_models:\n",
    "    predictions.append(model.predict(X_test))\n",
    "predictions=np.array(predictions)\n",
    "aggregated_predictions=np.mean(predictions,axis=0)\n",
    "\n",
    "# Round the aggregated predictions to the nearest integer\n",
    "aggregated_predictions = np.round(aggregated_predictions)\n",
    "\n",
    "bagging_accuracy=accuracy_score(y_test,aggregated_predictions)\n",
    "print(f\"Accuracy of Bagging classifier: {bagging_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_base_train, X_meta_train_split, y_base_train, y_meta_train_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)\n",
    "# Create a new dataset with predictions from base models\n",
    "meta_X = np.array([model.predict(X_test) for model in lr_models]).T\n",
    "X_meta_train = np.array([model.predict(X_meta_train_split) for model in lr_models]).T\n",
    "\n",
    "# Train a meta classifier (another LR model)\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_meta_train, y_meta_train_split)\n",
    "\n",
    "# Make predictions using the stacking ensemble\n",
    "stacking_preds = meta_model.predict(np.array([model.predict(X_test) for model in lr_models]).T)\n",
    "\n",
    "stacking_acc = accuracy_score(y_test, np.round(stacking_preds))\n",
    "print(f\"Stacking Ensemble Accuracy: {stacking_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
